# Project-3.SnakesID
Machine Learning applied to image recognition 
In this project, we used the pre-trained VGG-19 Machine Learning Model, and trained it with new images to extend its capabilities and get it to do a better job identifying snakes in Texas. VGG-19 is a convolutional neural network (In deep learning, this is a class of deep neural networks, most commonly applied to analyzing visual imagery) that is trained on more than a million images from the ImageNet database, is 19 layers deep, and can classify images into 1000 object categories, such as keyboard, pencil, and many animals. The basic idea of transfer learning is to extend an existing model that has been trained on very large datasets, by removing the last layer of the pre-trained model, which contains neurons representing the classification of the image. In the case of categorizing snake species, we fixed all but the last layer to their pre-trained weights, replacing the last layer with the species of snakes we wanted to categorize, and working it to differentiate between venomous and non-venomous snakes in Texas. 
